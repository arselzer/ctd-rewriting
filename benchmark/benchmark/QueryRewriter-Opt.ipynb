{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc19a7bd-f217-4c8e-ac44-3338cdba5555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/dist-packages (2.9.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (2.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.5/200.5 KB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: py4j\n",
      "Successfully installed py4j-0.10.9.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 install psycopg2-binary\n",
    "pip3 install networkx\n",
    "pip3 install colorama\n",
    "pip3 install termcolor\n",
    "pip3 install py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "22c176f2-3472-4700-b6de-0643b13812b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import psycopg2\n",
    "from pathlib import Path\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import ctdPython\n",
    "from functools import partial\n",
    "import sys\n",
    "from py4j.java_gateway import JavaGateway\n",
    "#from ctdPython.hypergraph import HyperGraph\n",
    "#from ctdPython.ctdcheck import CTDCheck\n",
    "#from ctdPython.ctdcheck import Block\n",
    "#from ctdPython.ctdcheck import VertSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "549c9b76-77e9-4fcf-af41-60a1faccfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import re\n",
    "import pprint\n",
    "import itertools\n",
    "import colorama\n",
    "from termcolor import colored\n",
    "import functools\n",
    "colorama.init()\n",
    "\n",
    "\n",
    "class Edge(object):\n",
    "    def __init__(self,V,name):\n",
    "        assert(type(name) == str)\n",
    "        assert(type(V) == set)\n",
    "        self.V = V\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.name + \"(\" + \",\".join(map(str,self.V)) + \")\"\n",
    "\n",
    "class HyperGraph(object):\n",
    "    def __init__(self):\n",
    "        self.V = set()\n",
    "        self.E = list()\n",
    "        self.edge_dict = dict()\n",
    "\n",
    "    def grid(n, m):\n",
    "        h = HyperGraph()\n",
    "        hc, vc = 0, 0\n",
    "        for col in range(m-1):\n",
    "            for row in range(n):\n",
    "                vi = '{}.{}'.format(row, col)\n",
    "                vright = '{}.{}'.format(row, col+1)\n",
    "                horz_name = 'H{}'.format(hc)\n",
    "                hc = hc+1\n",
    "                h.add_edge(set([vi, vright]),\n",
    "                           horz_name)\n",
    "        for col in range(m):\n",
    "            for row in range(n-1):\n",
    "                vi = '{}.{}'.format(row, col)\n",
    "                vdown = '{}.{}'.format(row+1, col)\n",
    "                vert_name = 'V{}'.format(vc)\n",
    "                vc = vc+1\n",
    "                h.add_edge(set([vi, vdown]),\n",
    "                           vert_name)\n",
    "        return h\n",
    "\n",
    "    def copy(self):\n",
    "        h = HyperGraph()\n",
    "        for en, e in self.edge_dict.items():\n",
    "            h.add_edge(e.V, name=en)\n",
    "        return h\n",
    "\n",
    "    def join_copy(self, x, y):\n",
    "        \"\"\"Copy of self with vertices x and y joined\"\"\"\n",
    "        if x not in self.V or y not in self.V:\n",
    "            raise ValueError('Join vertices need to be in hypergraph')\n",
    "        h = HyperGraph()\n",
    "        for en, e in self.edge_dict.items():\n",
    "            e2 = e.V.copy()\n",
    "            if y in e2:\n",
    "                e2.remove(y)\n",
    "                e2.add(x)\n",
    "            h.add_edge(e2, name=en)\n",
    "        return h\n",
    "\n",
    "    def toHyperbench(self):\n",
    "        s = []\n",
    "        for en, e in sorted(self.edge_dict.items()):\n",
    "            s.append('{}({}),'.format(en, ','.join(e.V)))\n",
    "        return '\\n'.join(s)\n",
    "\n",
    "    def vertex_induced_subg(self, U):\n",
    "        \"\"\"Induced by vertex set U\"\"\"\n",
    "        h = HyperGraph()\n",
    "        for en, e in self.edge_dict.items():\n",
    "            e2 = e.V.copy()\n",
    "            e2 = e2 & U\n",
    "            if e2 != set():\n",
    "                h.add_edge(e2, name=en)\n",
    "        return h\n",
    "\n",
    "    def bridge_subg(self, U):\n",
    "        EC = [en for en, e in self.edge_dict.items() if\n",
    "              (e.V & U) != set()]\n",
    "        C = self.edge_subg(EC)\n",
    "\n",
    "        # for each component C_i of rest, compute a special edge Sp_i\n",
    "        for C_i in self.separate(U):\n",
    "            print(C_i)\n",
    "            Sp_i_parts = [(e.V - U) for e in C.E if (e.V & C_i.V) != set()]\n",
    "            Sp_i = set.union(*Sp_i_parts)\n",
    "            C.add_special_edge(Sp_i)\n",
    "        return C\n",
    "\n",
    "    def edge_subg(self, edge_names):\n",
    "        h = HyperGraph()\n",
    "        for en in edge_names:\n",
    "            if en not in self.edge_dict:\n",
    "                raise ValueError('Edge >{}< not present in hypergraph'.format(en))\n",
    "            h.add_edge(self.edge_dict[en].copy(), en)\n",
    "        return h\n",
    "\n",
    "    def fromHyperbench(fname):\n",
    "        EDGE_RE = re.compile('\\s*([\\w:]+)\\s?\\(([^\\)]*)\\)')\n",
    "        def split_to_edge_statements(s):\n",
    "            x = re.compile('\\w+\\s*\\([^\\)]+\\)')\n",
    "            return list(x.findall(s))\n",
    "\n",
    "        def cleanup_lines(rl):\n",
    "            a = map(str.rstrip, rl)\n",
    "            b = filter(lambda x: not x.startswith('%') and len(x) > 0, a)\n",
    "            return split_to_edge_statements(''.join(b))\n",
    "\n",
    "        def line_to_edge(l):\n",
    "            m = EDGE_RE.match(l)\n",
    "            name = m.group(1)\n",
    "            e = m.group(2).split(',')\n",
    "            e = set(map(str.strip, e))\n",
    "            return name, e            \n",
    "\n",
    "        with open(fname) as f:\n",
    "            raw_lines = f.readlines()\n",
    "        lines = cleanup_lines(raw_lines)\n",
    "\n",
    "        hg = HyperGraph()\n",
    "        for l in lines:\n",
    "            edge_name, edge = line_to_edge(l)\n",
    "            hg.add_edge(edge, edge_name)\n",
    "        return hg\n",
    "\n",
    "    def add_edge(self, edge, name):\n",
    "        assert(type(edge) == set)\n",
    "        obj = Edge(edge,name)\n",
    "        self.edge_dict[name] = obj\n",
    "        self.V.update(edge)\n",
    "        self.E.append(obj)\n",
    "\n",
    "    def add_special_edge(self, sp):\n",
    "        SPECIAL_NAME = 'Special'\n",
    "        # find a name first\n",
    "        sp_name = None\n",
    "        for i in itertools.count():\n",
    "            candidate = SPECIAL_NAME + str(i)\n",
    "            if candidate not in self.edge_dict:\n",
    "                sp_name = candidate\n",
    "                break\n",
    "        self.add_edge(sp, sp_name)\n",
    "\n",
    "    def remove_edge(self, name):\n",
    "        e = self.edge_dict[name]\n",
    "        del self.edge_dict[name]\n",
    "        self.E.remove(e)\n",
    "\n",
    "    def primal_nx(self):\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(self.V)\n",
    "        for i, e in enumerate(self.E):\n",
    "            for a, b in itertools.combinations(e.V, 2):\n",
    "                G.add_edge(a, b)\n",
    "        return G\n",
    "\n",
    "    def incidence_nx(self, without=[]):\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(self.V)\n",
    "        G.add_nodes_from(self.edge_dict.keys())\n",
    "        for n, e in self.edge_dict.items():\n",
    "            if n in without:\n",
    "                continue\n",
    "            for v in e.V:\n",
    "                G.add_edge(n, v)\n",
    "        return G\n",
    "\n",
    "    def toPACE(self, special=[]):\n",
    "        buf = list()\n",
    "        vertex2int = {v: str(i) for i, v in enumerate(self.V, start=1)}\n",
    "        buf.append('p htd {} {}'.format(len(self.V),\n",
    "                                        len(self.E)))\n",
    "        for i, ei in enumerate(sorted(self.edge_dict.items()), start=1):\n",
    "            en, e = ei.V\n",
    "            edgestr = ' '.join(map(lambda v: vertex2int[v], e))\n",
    "            line = '{} {}'.format(i, edgestr)\n",
    "            buf.append(line)\n",
    "\n",
    "        if special is None:\n",
    "            special = []\n",
    "        for sp in special:\n",
    "            if sp is None:\n",
    "                continue\n",
    "            edgestr = ' '.join(map(lambda v: vertex2int[v], sp))\n",
    "            buf.append('s ' + edgestr)\n",
    "        return '\\n'.join(buf)\n",
    "\n",
    "    def separation_subg(self, U, sep):\n",
    "        C = HyperGraph()\n",
    "        cover = U | sep\n",
    "        for en, e in self.edge_dict.items():\n",
    "            if e.V.issubset(cover) and not e.V.issubset(sep):\n",
    "                C.add_edge(e.V, en)\n",
    "        return C\n",
    "\n",
    "    def separate(self, sep, only_vertices=False):\n",
    "        \"\"\"Returns list of components\"\"\"\n",
    "        assert(type(sep) == set)\n",
    "        primal = self.primal_nx()\n",
    "        primal.remove_nodes_from(sep)\n",
    "        comp_vertices = nx.connected_components(primal)\n",
    "        if only_vertices:\n",
    "            return list(comp_vertices)\n",
    "        comps = [self.separation_subg(U, sep)\n",
    "                 for U in comp_vertices]\n",
    "        return comps\n",
    "\n",
    "    def toVisualSC(self):\n",
    "        vertex2int = {v: str(i) for i, v in enumerate(self.V, start=1)}\n",
    "        edges = map(lambda e: map(lambda v: vertex2int[v], e.V), self.E)\n",
    "        buf = []\n",
    "        for e in edges:\n",
    "            buf.append('{'+', '.join(e) + '}')\n",
    "        return ' '.join(buf)\n",
    "\n",
    "    def fancy_repr(self, hl=[]):\n",
    "        edge_style = colorama.Fore.RED + colorama.Style.NORMAL\n",
    "        vertex_style = colorama.Fore.YELLOW + colorama.Style.NORMAL\n",
    "        hl_style = colorama.Fore.WHITE + colorama.Back.GREEN + colorama.Style.BRIGHT\n",
    "        _reset = colorama.Style.RESET_ALL\n",
    "\n",
    "        def color_vertex(v):\n",
    "            if v in hl:\n",
    "                return hl_style + v + _reset\n",
    "            else:\n",
    "                return vertex_style + v + _reset\n",
    "        s = ''\n",
    "        for en, e in sorted(self.edge_dict.items()):\n",
    "            s += edge_style + en + _reset + '('\n",
    "            s += ','.join(map(color_vertex, e.V))\n",
    "            s += ')\\n'\n",
    "        return s\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.fancy_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "773ddfea-7ee7-492b-b7f7-35a1b9a060a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertSet(object):\n",
    "    def __init__(self,vertices):\n",
    "        assert(type(vertices) == set)\n",
    "        self.vertices = vertices\n",
    "         \n",
    "    def __hash__(self):\n",
    "        finalHash = 0 \n",
    "        for h in self.vertices:\n",
    "            finalHash = finalHash + int(h)\n",
    "        return finalHash   \n",
    "        \n",
    "    def __repr__(self):        \n",
    "        return str(self.vertices)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return type(other) == VertSet and self.vertices == other.vertices\n",
    "\n",
    "class Block(object):\n",
    "    def __init__(self,head,cover,tail):\n",
    "        assert(type(head) == VertSet)\n",
    "        assert(type(tail) == VertSet)\n",
    "        assert(len(head.vertices.intersection(tail.vertices)) == 0) # disjoint\n",
    "        self.head = head\n",
    "        self.cover = cover\n",
    "        self.tail = tail\n",
    "\n",
    "    def __hash__(self):\n",
    "        finalHash = 0 \n",
    "        for h in self.head.vertices:\n",
    "            finalHash = finalHash + hash(h)\n",
    "        for t in self.tail.vertices:\n",
    "            finalHash = finalHash + hash(t)\n",
    "        return finalHash\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return type(other) == Block and self.head == other.head and self.tail == other.tail\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"Block(\"+str(self.head)+\",\"+str(self.tail)+\")\"\n",
    "\n",
    "\n",
    "    def __lt__(self,other):\n",
    "        selfVert = self.head.vertices.union(self.tail.vertices) \n",
    "        otherVert = other.head.vertices.union(other.tail.vertices) \n",
    "\n",
    "        return selfVert.issubset(otherVert) and self.tail.vertices.issubset(other.tail.vertices)\n",
    "\n",
    "    # connected bags filters out any bags for which the induced subgraph over E is not connected\n",
    "    def connected(self,H):\n",
    "        induced = H.vertex_induced_subg(self.head.vertices)\n",
    "        comps = induced.separate(set())\n",
    "        return len(comps) == 1 # connected if only one connected comp\n",
    "\n",
    "    def weight(self, H):\n",
    "        #print(\"induced: \" + str(H.covered_subg(self.head.vertices)))\n",
    "        #return len(H.covered_subg(self.head.vertices).E) ** 2\n",
    "        return len(self.cover) ** 2\n",
    "\n",
    "class Node:    \n",
    "    def __init__(self,bag,cover,children):\n",
    "        assert(type(bag) == VertSet)\n",
    "        self.bag = bag  # set of vertices\n",
    "        self.cover = cover #set of edges\n",
    "        self.children = children #set of child nodes\n",
    "\n",
    "    def addChild(self,child):\n",
    "        self.children.append(child)\n",
    "\n",
    "\n",
    "    def toString(self,depth):\n",
    "\n",
    "        tabby = \"\\n \" + \"\\t\" * depth\n",
    "        \n",
    "\n",
    "        childrenReps = list()\n",
    "        for child in self.children:\n",
    "            childrenReps.append(child.toString(depth+1))\n",
    "\n",
    "        return \"Bag: \" + str(self.bag) + \" Cover: \" + str(self.cover) + tabby + tabby.join(childrenReps)\n",
    "    \n",
    "    def __repr__(self):        \n",
    "        return self.toString(1)\n",
    "\n",
    "class NodeEncoder(JSONEncoder):\n",
    "    def default(self, o):\n",
    "        return {'bag': list(o.bag.vertices),\n",
    "                'cover': list([{'name': e.name, 'vertices': list(e.V)} for e in o.cover]),\n",
    "                'children': [self.default(c) for c in o.children]}\n",
    "\n",
    "class CTDOpt(object):\n",
    "    def __init__(self,h):\n",
    "        self.H = h                   # hypergraph\n",
    "        self.root_block = Block(VertSet(set()), set(), VertSet(h.V))\n",
    "        self.blocks = set([self.root_block])\n",
    "        self.satisfied_block = set() # indicating which blocks are satisfied\n",
    "        self.head_to_blocks = dict() # mapping heads to blocks headed by them\n",
    "        self.weights = dict() # maps block to weight\n",
    "        self.weights[self.root_block] = sys.maxsize\n",
    "        self.children = dict()\n",
    "        self.new_blocks = set()\n",
    "        self.head_to_cover = dict() # cache the edge covers\n",
    "        self.block_to_basis = dict() # mapping a satisfied block to its basis\n",
    "        self.rootHead = None # cache the root head once found\n",
    "\n",
    "    def addBlock(self,b):\n",
    "        assert(type(b) == Block)\n",
    "        if b in self.blocks:\n",
    "            return # don't add same block twice\n",
    "        self.blocks.add(b)\n",
    "        self.head_to_cover[b.head] = b.cover\n",
    "        self.new_blocks.add(b)\n",
    "        # print(\"Is the head \", b.head ,\" hash:\",hash(b.head)  ,\" already in the map \", list(self.head_to_blocks.keys()))\n",
    "        # print(\"Answer: \", b.head in list(self.head_to_blocks.keys()))\n",
    "        if b.head in self.head_to_blocks:\n",
    "            self.head_to_blocks[b.head].append(b)\n",
    "        else:\n",
    "            self.head_to_blocks[b.head] = [b]            \n",
    "        \n",
    "        if len(b.tail.vertices) == 0: \n",
    "            # print(\"Block \",b,\" added as trivially sat.\")\n",
    "            self.satisfied_block.add(b)  # check if trivially satisifed\n",
    "            self.weights[b] = b.weight(self.H)\n",
    "            self.children[b] = set()\n",
    "        else:\n",
    "            self.weights[b] = sys.maxsize\n",
    "        # else:\n",
    "        #     self.block_dict[b] = self.hasBasis(b) # basis check\n",
    "\n",
    "    def minimize_weights(self):\n",
    "        # new_blocks = blocks that were updated in the last iteration -> continue until there are no more updates\n",
    "        while self.new_blocks != set():\n",
    "            new = set() # keep track of newly added blocks to stop when nothing new is added\n",
    "            for b in self.blocks:\n",
    "                if len(b.tail.vertices) == 0:\n",
    "                    # skip trivial blocks\n",
    "                    continue\n",
    "                bases = self.determine_bases(b, self.new_blocks)\n",
    "                #print(\"block: \" + str(b))\n",
    "                #print(\"bases: \" + str(bases))\n",
    "                for basis in bases:\n",
    "                    #print(\"basis: \" + str(basis))\n",
    "                    new_weight = self.basis_weight(b, basis)\n",
    "                    #print(\"new weight: \" + str(new_weight) + \", old weight: \" + str(self.weights[b]))\n",
    "                    if new_weight < self.weights[b]:\n",
    "                        self.weights[b] = new_weight\n",
    "                        self.children[b] = basis\n",
    "                        self.block_to_basis[b] = basis\n",
    "                        #print(\"best weight. children: \" + str(basis))\n",
    "                        new.add(b)\n",
    "            print(\"new blocks: \" + str(new))\n",
    "            # print(\"children: \")\n",
    "            # for p in self.children:\n",
    "            #     c = self.children[p]\n",
    "            #     if c != set():\n",
    "            #         print(str(p) + \": \" + str(c))\n",
    "            self.new_blocks = new\n",
    "        if self.weights[self.root_block] == sys.maxsize:\n",
    "            print(\"no decomposition found\")\n",
    "            return None\n",
    "        else:\n",
    "            decomp = self.construct_td()\n",
    "            print(\"decomposition found: \" + str(decomp))\n",
    "            #print(\"root block children\", self.children[self.root_block])\n",
    "            return decomp\n",
    "\n",
    "    def construct_td(self):\n",
    "        return self.to_node(self.root_block)\n",
    "\n",
    "    def basis_weight(self, block, basis):\n",
    "        basis_sum = sum(list(map(lambda b: self.weights[b], basis)))\n",
    "        return block.weight(self.H) + basis_sum\n",
    "\n",
    "\n",
    "    # determine the bases of a block wrt. new blocks (one of the blocks has to be from new_blocks)\n",
    "    # a basis is a set of blocks\n",
    "    def determine_bases(self, b, new_blocks):\n",
    "        bases = []\n",
    "        #print(\"block: \" + str(b))\n",
    "        for head in self.head_to_blocks:\n",
    "            #print(\"head: \" + str(head))\n",
    "            allBlocks = self.head_to_blocks[head]\n",
    "            #print(\"allblocks: \" + str(allBlocks))\n",
    "            headed_blocks = [x for x in allBlocks if x < b and x != b]\n",
    "            #print(\"headed blocks: \" + str(headed_blocks))\n",
    "\n",
    "            if set(headed_blocks).intersection(new_blocks) == set():\n",
    "                continue\n",
    "\n",
    "            for ob in headed_blocks:\n",
    "                if self.weights[ob] == sys.maxsize:\n",
    "                    continue\n",
    "\n",
    "            # 3. condition (for each component C_i', the block (B', C_i') is satisfied\n",
    "            cond3 = True\n",
    "            for ob in headed_blocks:\n",
    "                if not ob in self.satisfied_block:\n",
    "                    cond3 = False\n",
    "            if cond3 == False:\n",
    "                #print(\"cond3 broken\")\n",
    "                continue #3nd Condition violated (testing first for efficiency)\n",
    "\n",
    "            # 1. condition (the tail of the block b is a subset of the union of\n",
    "            # the tails and the head\n",
    "            unionTails = set()\n",
    "            # union of the tails' vertices\n",
    "            for ob in headed_blocks:\n",
    "                for v in ob.tail.vertices:\n",
    "                    unionTails.add(v)\n",
    "            # add the head's vertices\n",
    "            for v in head.vertices:\n",
    "                unionTails.add(v)\n",
    "            if not b.tail.vertices.issubset(unionTails):\n",
    "                #print(\"cond1 broken\")\n",
    "                continue # 1st Condition violated\n",
    "\n",
    "            # 2. condition (each hyperedge partially contained in the tail of b has to be contained\n",
    "            # in the union of the tails and the head)\n",
    "            cond2 = True\n",
    "            for e in self.H.E:\n",
    "                if len(e.V.intersection(b.tail.vertices)) == 0:\n",
    "                    continue # find other edge\n",
    "                if not e.V.issubset(unionTails):\n",
    "                    cond2 = False\n",
    "                    #print(\"cond2 broken\")\n",
    "                    break\n",
    "            if cond2 == False:\n",
    "                continue # 2nd Condition violated\n",
    "\n",
    "            # basis found!\n",
    "            basis = set()\n",
    "            for ob in headed_blocks:\n",
    "                basis.add(ob)\n",
    "            bases.append(basis)\n",
    "            #print(\"bases: \" + str(bases))\n",
    "        if bases != []:\n",
    "            self.satisfied_block.add(b)\n",
    "        return bases\n",
    "\n",
    "    def hasBasis(self,b):\n",
    "        basisFound = False\n",
    "        basisWitness = None\n",
    "        for B in self.head_to_blocks:\n",
    "            allBlocks = self.head_to_blocks[B]\n",
    "            blocks = [x for x in allBlocks if x < b]\n",
    "\n",
    "            cond3 = True\n",
    "            for ob in blocks:\n",
    "                if not ob in self.satisfied_block:\n",
    "                    cond3 = False\n",
    "            if cond3 == False:\n",
    "                continue #3nd Condition violated (testing first for efficiency)\n",
    "\n",
    "            unionTails = set()\n",
    "            for ob in blocks:\n",
    "                for v in ob.tail.vertices:\n",
    "                    unionTails.add(v)\n",
    "            for v in B.vertices:\n",
    "                unionTails.add(v)\n",
    "            if not  b.tail.vertices.issubset(unionTails):\n",
    "                continue # 1st Condition violated\n",
    "            cond2 = True\n",
    "            for e in self.H.E:\n",
    "                if len(e.V.intersection(b.tail.vertices)) == 0:\n",
    "                    continue # find other edge\n",
    "                if not e.V.issubset(unionTails):\n",
    "                    cond2 = False\n",
    "                    break\n",
    "            if cond2 == False:\n",
    "                continue # 2nd Condition vioalted\n",
    "            basisFound = True\n",
    "            basisWitness = B\n",
    "            # print(\"The basis of \", b , \" is \", B)\n",
    "            # print(\"The blocks headed by \", B)\n",
    "            # for BB in blocks:\n",
    "            #     print(str(BB)+\"\\n\")\n",
    "\n",
    "            break\n",
    "        if basisFound == True:\n",
    "            self.satisfied_block.add(b)\n",
    "            self.block_to_basis[b] = basisWitness\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def rootHeadFound(self):\n",
    "        for head in self.head_to_blocks:\n",
    "            blocks = self.head_to_blocks[head]\n",
    "            allSatisfied = True\n",
    "            for b in blocks:\n",
    "                if not b in self.satisfied_block:\n",
    "                    allSatisfied = False\n",
    "            if allSatisfied == True:\n",
    "                # print(\"Root Head is \",head)\n",
    "                self.rootHead = head\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def hasDecomp(self):\n",
    "        while True:            \n",
    "            changed = False\n",
    "            for b in self.blocks:\n",
    "                if b in self.satisfied_block:\n",
    "                    continue # already marked as satisfied\n",
    "                res = self.hasBasis(b)\n",
    "                if res == True:\n",
    "                    changed = True\n",
    "                    #print(\"Found basis for the block \", b)\n",
    "                if self.rootHeadFound():\n",
    "                    # print(\"Found decomp!\")\n",
    "                    return True\n",
    "            if changed == False:\n",
    "                # print(\"Nothing has changed anymore, terminating\")\n",
    "                return False\n",
    "\n",
    "    def to_node(self,block):\n",
    "        if not(block in self.satisfied_block):\n",
    "            # print(block, \" is not satisfied\")\n",
    "            return None  # Nothing to return if block not satisfied\n",
    "        if len(block.tail.vertices) == 0:\n",
    "            # print(block, \" is trivial\")\n",
    "            return Node(block.head,self.head_to_cover[block.head],list()) # leaf node\n",
    "        basis = self.block_to_basis[block]\n",
    "\n",
    "        node_children = list()\n",
    "        for block_child in self.children[block]:\n",
    "            if len(block_child.tail.vertices) != 0:\n",
    "                node_children.append(self.to_node(block_child))\n",
    "\n",
    "        basis_head = list(basis)[0].head\n",
    "        return Node(basis_head,self.head_to_cover[basis_head],node_children)\n",
    "\n",
    "    def getDecomp(self,block):\n",
    "        if not(block in self.satisfied_block):\n",
    "            # print(block, \" is not satisfied\")\n",
    "            return None  # Nothing to return if block not satisfied\n",
    "        if len(block.tail.vertices) == 0:\n",
    "            # print(block, \" is trivial\")\n",
    "            return Node(block.head,self.head_to_cover[block.head],list()) # leaf node\n",
    "        basis = self.block_to_basis[block]\n",
    "        allBlocks = self.head_to_blocks[basis]\n",
    "        blocks = [x for x in allBlocks if x < block]\n",
    "\n",
    "        # print(\"Child BLocks for block \", block)\n",
    "        # for bs in allBlocks:\n",
    "        #     print(bs)\n",
    "\n",
    "        children = list()\n",
    "        for bs in blocks: \n",
    "            children.append(self.getDecomp(bs))\n",
    "        \n",
    "        return Node(basis,self.head_to_cover[basis],children)\n",
    "\n",
    "\n",
    "    def getDecompRoot(self):\n",
    "        if self.rootHead == None:\n",
    "            return None  ## can't find decomp of whole graph if no root head\n",
    "\n",
    "        allBlocks = self.head_to_blocks[self.rootHead]\n",
    "        # print(\"Blocks of RootHead\")\n",
    "        # for bs in allBlocks:\n",
    "        #     print(bs)\n",
    "\n",
    "\n",
    "        blocks = [x for x in allBlocks if len(x.tail.vertices) != 0]\n",
    "\n",
    "        # print(\"Non-Trivial Blocks of RootHead\")\n",
    "        # for bs in blocks:\n",
    "        #     print(bs)\n",
    "\n",
    "        children = list()\n",
    "        for bs in blocks:\n",
    "            children.append(self.getDecomp(bs))\n",
    "\n",
    "        return Node(self.rootHead,self.head_to_cover[self.rootHead],children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c147f0ff-21f0-4510-9f43-136f6dabc061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_choose_k(S, k):\n",
    "    from itertools import chain, combinations\n",
    "    return chain(*(combinations(S, kp) for kp in range(1,k+1)))\n",
    "#\n",
    "def all_lambdas(E, k):\n",
    "    for es in all_choose_k(E, k):\n",
    "        # yield set.union(*es)\n",
    "        yield es\n",
    "\n",
    "# (over approximates) the bags produced by the LogK algorithm\n",
    "def computesoftk(h, k):\n",
    "    softk = list()\n",
    "    for P in all_lambdas(h.E,k):\n",
    "        obj1 = set()\n",
    "        if len(P) == 1:\n",
    "            obj1 = P[0].V\n",
    "        elif len(P) > 1:\n",
    "            obj1 =functools.reduce(lambda a,b: (a).union(b),map(lambda s : s.V,P))\n",
    "        for C in h.separate(obj1, only_vertices=True):\n",
    "            for L in all_lambdas(h.E, k):\n",
    "                obj2 = set()\n",
    "                if len(L) == 1:\n",
    "                    obj2 = L[0].V\n",
    "                elif len(L) > 1:\n",
    "                    obj2 = functools.reduce(lambda a,b: (a).union(b),map(lambda s : s.V,L))\n",
    "                B = set.intersection(C, obj2)\n",
    "                if len(B) > 1 and B not in softk:\n",
    "                    softk.append((B,L))\n",
    "    return softk\n",
    "    \n",
    "# computes the blocks of a bag by computing its components w.r.t. h\n",
    "def bag_to_blocks(h,pair):\n",
    "    B = pair[0]\n",
    "    L = pair[1]  \n",
    "    blocks = list()\n",
    "    for C in h.separate(B, only_vertices=True):\n",
    "        blocks.append(Block(VertSet(B),VertSet(C)))\n",
    "    blocks.append(Block(VertSet(B),L,VertSet(set())))  # adding trivial block too\n",
    "    return blocks\n",
    "\n",
    "\n",
    "# computes the blocks of a bag by computing its components w.r.t. h\n",
    "def bag_to_blocksConnected(h,pair):\n",
    "    B = pair[0]\n",
    "    L = pair[1]  \n",
    "    blocks = list()\n",
    "    for C in h.separate(B, only_vertices=True):\n",
    "        tempBlock = Block(VertSet(B),L,VertSet(C))\n",
    "        if tempBlock.connected(h):\n",
    "            blocks.append(tempBlock)\n",
    "    tmp = Block(VertSet(B),L,VertSet(set()))\n",
    "    if tmp.connected(h):\n",
    "        blocks.append(tmp)  # adding trivial block too\n",
    "    return blocks\n",
    "\n",
    "\n",
    "# Same as  computeosftK, but returns directly the blocks\n",
    "def computesoftkBlocks(h, k):\n",
    "    out = list()\n",
    "    listOfLists = map(partial(bag_to_blocks,h),computesoftk(h,k))\n",
    "    for ll in listOfLists:\n",
    "        for l in ll:\n",
    "            out.append(l)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Same as  computeosftK, but returns directly the blocks\n",
    "def computesoftkBlocksConnected(h, k):\n",
    "    out = list()\n",
    "    listOfLists = map(partial(bag_to_blocksConnected,h),computesoftk(h,k))\n",
    "    for ll in listOfLists:\n",
    "        for l in ll:\n",
    "            out.append(l)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ba964037-c211-464b-a57e-bc98a50de1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "REWRITE_JAR = 'rewrite-assembly-0.1.0-SNAPSHOT.jar'\n",
    "\n",
    "class Rewriting:\n",
    "    def __init__(self, original, rewritten, features, time, drop_statements):\n",
    "        self.original = original\n",
    "        self.rewritten = rewritten\n",
    "        self.features = features\n",
    "        self.time = time\n",
    "        self.drop_statements = drop_statements\n",
    "\n",
    "class QueryRewriter:\n",
    "    def __init__(self, host, database, user, password, port=5432):\n",
    "        self.host = host\n",
    "        self.database = database\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.port = port\n",
    "        self.jdbcString = f'jdbc:postgresql://{self.host}:{self.port}/{self.database}'\n",
    "\n",
    "        self.rewrite_process = subprocess.Popen(['java', '-jar', REWRITE_JAR], stdout=subprocess.PIPE)\n",
    "\n",
    "        # Wait for the first line which is printed after the py4j server is started)\n",
    "        line = self.rewrite_process.stdout.readline()\n",
    "        print(line)\n",
    "\n",
    "        gateway = JavaGateway()\n",
    "\n",
    "        self.rewriter = gateway.entry_point\n",
    "        self.rewriter.connect(self.jdbcString, self.database, self.user, self.password)\n",
    "\n",
    "    def rewrite(self, query):\n",
    "        self.rewriter.connect(self.jdbcString, self.database, self.user, self.password)\n",
    "        self.rewriter.rewrite(query)\n",
    "\n",
    "        output = json.loads(Path('output/output.json').read_text())\n",
    "        drop_output = json.loads(Path('output/drop.json').read_text())\n",
    "\n",
    "        result = Rewriting(query, output['rewritten_query'], output['features'], output['time'],\n",
    "                           drop_output['rewritten_query'])\n",
    "\n",
    "        hg = HyperGraph.fromHyperbench('output/hypergraph.txt')\n",
    "\n",
    "        acyclic = output['acyclic']\n",
    "\n",
    "        if acyclic == True:\n",
    "            print(\"query is acyclic. done\")\n",
    "            return \"acyclic\"\n",
    "        \n",
    "        print('hg: ' + str(hg))\n",
    "        ctd = CTDOpt(hg)\n",
    "        print('ctd: ' + str(ctd))\n",
    "        blocks = computesoftkBlocksConnected(hg,3)\n",
    "\n",
    "        for b in blocks:\n",
    "            ctd.addBlock(b)\n",
    "\n",
    "        res = ctd.minimize_weights()\n",
    "        print(\"Result: \",res)\n",
    "\n",
    "        output = self.rewriter.rewriteCyclicJSON(json.dumps(res, cls=NodeEncoder))\n",
    "        print(output)\n",
    "        \n",
    "        #print(ctd.root_block)\n",
    "\n",
    "        #res = ctd.hasDecomp()\n",
    "\n",
    "        #decomp = ctd.getDecompRoot()\n",
    "        #print(\"Found decomposition \\n\", decomp)\n",
    "        #print(\"weights: \" + str(ctd.weights))\n",
    "\n",
    "        # try:\n",
    "        #     rewriter.stopServer()\n",
    "        # except Py4JError:\n",
    "        #     print('Server stopped')\n",
    "        for l in self.rewrite_process.stdout.readline():\n",
    "            print(l)\n",
    "        return result\n",
    "        \n",
    "    def close(self):\n",
    "        self.rewrite_process.kill()\n",
    "\n",
    "#result = rewriter.rewrite(query)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bffb7d23-133b-4e60-b08c-b02c8c96d729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Py4j server started\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: No SLF4J providers were found.\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.\n",
      "ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is acyclic. done\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT MIN(p.Id) FROM posts as p, postLinks as pl, postHistory as ph, votes as v, badges as b, users as u WHERE p.Id = pl.RelatedPostId AND u.Id = p.OwnerUserId AND u.Id = b.UserId AND u.Id = ph.UserId AND u.Id = v.UserId AND p.AnswerCount>=0 AND p.FavoriteCount>=0 AND pl.LinkTypeId=1 AND ph.PostHistoryTypeId=2 AND v.CreationDate>=CAST('2010-07-20 00:00:00' AS TIMESTAMP) AND u.Reputation>=1 AND u.DownVotes>=0 AND u.DownVotes<=0 AND u.UpVotes<=439 AND u.CreationDate<=CAST('2014-08-07 11:18:45' AS TIMESTAMP)\n",
    "\"\"\"\n",
    "\n",
    "rewriter = QueryRewriter('postgres', 'stats', 'stats', 'stats')\n",
    "\n",
    "result = rewriter.rewrite(query)\n",
    "\n",
    "rewriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1bcf9a21-0a87-4878-a672-cb80a91f54fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Py4j server started\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: No SLF4J providers were found.\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.\n",
      "ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg: E1(7,3)\n",
      "E2(9,3)\n",
      "E3(11,3)\n",
      "E4(7,12)\n",
      "E5(13,9)\n",
      "E6(11,15)\n",
      "E7(13,12)\n",
      "E8(13,15)\n",
      "E9(12,15)\n",
      "\n",
      "ctd: <__main__.CTDOpt object at 0x74871b1160e0>\n",
      "new blocks: {Block({'11', '13', '3', '15'},{'9'}), Block({'13', '9', '3', '15'},{'11'}), Block({'13', '9', '12', '3'},{'7'}), Block({'13', '7', '12', '3'},{'9'}), Block({'7', '12', '3', '15'},{'11'}), Block({'9', '15', '12', '13', '7'},{'11', '3'}), Block({'7', '12', '15'},{'11', '13', '9', '3'}), Block(set(),{'11', '9', '15', '12', '13', '7', '3'}), Block({'11', '15', '12', '13', '7'},{'9', '3'}), Block({'11', '9', '15', '7', '3'},{'13', '12'}), Block({'11', '12', '3', '15'},{'7'}), Block({'11', '9', '12', '7', '3'},{'13', '15'}), Block({'11', '9', '15', '12', '13'},{'7', '3'}), Block({'11', '9', '13', '7', '3'},{'12', '15'})}\n",
      "new blocks: {Block({'7', '12'},{'11', '9', '15', '13', '3'}), Block({'13', '9'},{'11', '15', '12', '7', '3'}), Block({'13', '12'},{'11', '9', '15', '7', '3'}), Block({'13', '15'},{'11', '9', '12', '7', '3'}), Block({'7', '9', '12', '13'},{'11', '15', '3'}), Block({'7', '12', '13'},{'11', '15', '9', '3'}), Block({'7', '12', '15', '13'},{'11', '9', '3'}), Block({'11', '7', '3'},{'13', '9', '12', '15'}), Block({'7', '12', '3'},{'11', '13', '9', '15'}), Block({'11', '3'},{'9', '15', '12', '13', '7'}), Block({'9', '3'},{'11', '15', '12', '13', '7'}), Block({'11', '15'},{'9', '12', '13', '7', '3'}), Block({'11', '13', '9', '3'},{'7', '12', '15'}), Block({'11', '9', '3'},{'13', '7', '12', '15'}), Block({'11', '3', '15'},{'13', '9', '12', '7'}), Block({'13', '9', '3'},{'11', '7', '12', '15'}), Block({'11', '13', '9', '15'},{'7', '12', '3'}), Block({'11', '9', '3', '15'},{'7', '12', '13'}), Block({'11', '13', '15'},{'7', '9', '12', '3'}), Block({'7', '3'},{'11', '9', '15', '12', '13'}), Block({'11', '7', '12', '15'},{'13', '9', '3'}), Block({'11', '12', '15'},{'13', '9', '7', '3'}), Block({'11', '7', '3', '15'},{'13', '9', '12'}), Block({'11', '7', '12', '3'},{'13', '9', '15'}), Block({'11', '13', '12', '15'},{'7', '9', '3'}), Block({'13', '9', '12'},{'11', '15', '7', '3'}), Block({'13', '9', '15'},{'11', '7', '12', '3'}), Block({'13', '9', '12', '15'},{'11', '7', '3'}), Block({'13', '12', '15'},{'11', '7', '9', '3'}), Block({'12', '15'},{'11', '9', '13', '7', '3'}), Block({'11', '7', '9', '3'},{'13', '12', '15'}), Block({'7', '9', '12', '3'},{'11', '13', '15'}), Block({'13', '9', '7', '3'},{'11', '12', '15'}), Block({'7', '9', '3'},{'11', '13', '12', '15'})}\n",
      "new blocks: set()\n",
      "decomposition found: Bag: {'9', '15', '12', '13', '7'} Cover: (E4(7,12), E5(13,9), E8(13,15))\n",
      " \tBag: {'11', '9', '15', '7', '3'} Cover: (E4(7,12), E2(9,3), E6(11,15))\n",
      " \t\t\n",
      "Result:  Bag: {'9', '15', '12', '13', '7'} Cover: (E4(7,12), E5(13,9), E8(13,15))\n",
      " \tBag: {'11', '9', '15', '7', '3'} Cover: (E4(7,12), E2(9,3), E6(11,15))\n",
      " \t\t\n",
      "TreeNode(Set(E4($12, $7), E5($13, $9), E8($13, $15)))[Set(_)] [[parent: false]]\n",
      "-- TreeNode(Set(E4($12, $7), E2($9, $3), E6($15, $11)))[Set(_)] [[parent: true]]\n",
      "\n",
      "87\n",
      "65\n",
      "82\n",
      "78\n",
      "73\n",
      "78\n",
      "71\n",
      "58\n",
      "32\n",
      "115\n",
      "117\n",
      "110\n",
      "46\n",
      "114\n",
      "101\n",
      "102\n",
      "108\n",
      "101\n",
      "99\n",
      "116\n",
      "46\n",
      "82\n",
      "101\n",
      "102\n",
      "108\n",
      "101\n",
      "99\n",
      "116\n",
      "105\n",
      "111\n",
      "110\n",
      "46\n",
      "103\n",
      "101\n",
      "116\n",
      "67\n",
      "97\n",
      "108\n",
      "108\n",
      "101\n",
      "114\n",
      "67\n",
      "108\n",
      "97\n",
      "115\n",
      "115\n",
      "32\n",
      "105\n",
      "115\n",
      "32\n",
      "110\n",
      "111\n",
      "116\n",
      "32\n",
      "115\n",
      "117\n",
      "112\n",
      "112\n",
      "111\n",
      "114\n",
      "116\n",
      "101\n",
      "100\n",
      "46\n",
      "32\n",
      "84\n",
      "104\n",
      "105\n",
      "115\n",
      "32\n",
      "119\n",
      "105\n",
      "108\n",
      "108\n",
      "32\n",
      "105\n",
      "109\n",
      "112\n",
      "97\n",
      "99\n",
      "116\n",
      "32\n",
      "112\n",
      "101\n",
      "114\n",
      "102\n",
      "111\n",
      "114\n",
      "109\n",
      "97\n",
      "110\n",
      "99\n",
      "101\n",
      "46\n",
      "10\n",
      "<__main__.Rewriting object at 0x7487190dc250>\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT MIN(pkp1.Person1Id)\n",
    "FROM City AS CityA\n",
    "JOIN City AS CityB\n",
    "  ON CityB.isPartOf_CountryId = CityA.isPartOf_CountryId\n",
    "JOIN City AS CityC\n",
    "  ON CityC.isPartOf_CountryId = CityA.isPartOf_CountryId\n",
    "JOIN Person AS PersonA\n",
    "  ON PersonA.isLocatedIn_CityId = CityA.CityId\n",
    "JOIN Person AS PersonB\n",
    "  ON PersonB.isLocatedIn_CityId = CityB.CityId\n",
    "JOIN Person AS PersonC\n",
    "  ON PersonC.isLocatedIn_CityId = CityC.CityId\n",
    "JOIN Person_knows_Person AS pkp1\n",
    "  ON pkp1.Person1Id = PersonA.PersonId\n",
    " AND pkp1.Person2Id = PersonB.PersonId\n",
    "JOIN Person_knows_Person AS pkp2\n",
    "  ON pkp2.Person1Id = PersonB.PersonId\n",
    " AND pkp2.Person2Id = PersonC.PersonId\n",
    "JOIN Person_knows_Person AS pkp3\n",
    "  ON pkp3.Person1Id = PersonC.PersonId\n",
    " AND pkp3.Person2Id = PersonA.PersonId\n",
    "\"\"\"\n",
    "\n",
    "rewriter = QueryRewriter('postgres', 'lsqb', 'lsqb', 'lsqb')\n",
    "\n",
    "result = rewriter.rewrite(query)\n",
    "print(result)\n",
    "\n",
    "rewriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7c7ba327-b514-4d54-9dc5-d14a0366345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3ffa9163-d940-440a-baf1-65a0e7eb4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill rewriter process in case it was not stopped\n",
    "from psutil import process_iter\n",
    "from signal import SIGTERM\n",
    "\n",
    "for proc in process_iter():\n",
    "    for conns in proc.connections(kind='inet'):\n",
    "        if conns.laddr.port == 25333:\n",
    "            proc.send_signal(SIGTERM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f599c40e-4177-44fd-b2ae-ba341a58dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rewritten(query):\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"postgres\",\n",
    "        database=database,\n",
    "        user=database,\n",
    "        password=database\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8b8a0-786d-46b8-a62d-a55b9aafb3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
